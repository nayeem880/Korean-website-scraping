{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vocal-yugoslavia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required modules\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "developed-coach",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = pd.read_csv('parent_links.csv')\n",
    "urls = urls.drop(['Unnamed: 0'], axis = 1) \n",
    "pd.options.display.max_columns = 999\n",
    "pd.options.display.max_rows = 999\n",
    "\n",
    "t = pd.read_csv(\"toplinks.csv\")\n",
    "t = t.drop(['Unnamed: 0'], axis = 1)\n",
    "t = list(t[\"0\"])\n",
    "\n",
    "n = pd.read_csv(\"newlinks.csv\")\n",
    "n = n.drop(['Unnamed: 0'], axis = 1)\n",
    "n = list(n[\"0\"])\n",
    "\n",
    "alll = pd.read_csv(\"alllinks.csv\")\n",
    "alll = alll.drop(['Unnamed: 0'], axis = 1)\n",
    "alll = list(alll[\"0\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "technological-consultation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-alignment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "involved-outline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://class101.net/creative',\n",
       " 'https://class101.net/store',\n",
       " 'https://class101.net/money']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = list(urls['0'])\n",
    "b = b[:3]\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-breathing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "periodic-battle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://class101.net/creative\n",
      "while...\n",
      "Last height  5359\n",
      "New height  5359\n",
      "Quiting\n",
      "https://class101.net/store\n",
      "while...\n",
      "Last height  7920\n",
      "New height  7920\n",
      "Quiting\n",
      "https://class101.net/money\n",
      "while...\n",
      "Last height  5789\n",
      "New height  8066\n",
      "Last height  8066\n",
      "New height  10344\n",
      "Last height  10344\n",
      "New height  12621\n",
      "Last height  12621\n",
      "New height  14260\n",
      "Last height  14260\n",
      "New height  14260\n",
      "Quiting\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "all_item = []\n",
    "\n",
    "for i in range(len(b)):\n",
    "    url = b[i]\n",
    "    item = []\n",
    "    driver = webdriver.Chrome(r'C:\\Users\\USER\\chromedriver_win32\\chromedriver.exe')\n",
    "    \n",
    "    def getdata(url):\n",
    "        print(url)\n",
    "        \n",
    "        driver.get(url)\n",
    "\n",
    "        # Wait to load page\n",
    "        print('while...')\n",
    "\n",
    "        source_code = driver.page_source\n",
    "        soup = BeautifulSoup(source_code, 'html.parser')\n",
    "\n",
    "        initial = soup.find_all(\"div\", class_=['sc-dkiTmt', 'cQiUWe'])\n",
    "        for y in initial:\n",
    "            initialdiv = y.find_all('div', class_ = ['ProductHeader__Header-az1cmu-0 leqDJG','AffixProductHeader__StyledProductHeader-sc-1l73jdk-1','idfLTb'])\n",
    "            for p in initialdiv:              \n",
    "                top2 = p.find_all('div', class_ = ['sc-bdnylx','gGpzAi','ProductHeader__Tag-az1cmu-1','iOzkLq'])\n",
    "                for k in top2:\n",
    "                    if k.text not in item:\n",
    "                        item.append(k.text)\n",
    "\n",
    "                heading = p.find_all('h2', class_ = ['sc-bdnylx','cOMiUB','ProductHeader__Title-az1cmu-2','fkqBP'])\n",
    "                for j in heading:\n",
    "                    if j.text not in item:\n",
    "                        item.append(j.text)\n",
    "\n",
    "                recommend = p.find_all('div', class_=\"SalesProductInfoTable__Row-sc-1uyx5v1-1 gOzdaG\")\n",
    "                for r in recommend:\n",
    "                    t2 = r.find_all('div', class_ = ['SalesProductInfoTable__ButtonContainer-sc-1uyx5v1-5','jOtFPR','SalesProductInfoTable__StyledExperiment-sc-1uyx5v1-4','diAwWT'])\n",
    "                    for t in t2:\n",
    "                        each = t.find_all('button', class_ = [\"sc-ksluoS\", \"dyNqkJ\" ,\"sc-kfYqjs\", \"kpPRTM\",\"SalesProductInfoTable__WishlistButton-sc-1uyx5v1-2\", \"fxUQsM\"])\n",
    "                        for e in each:\n",
    "                            if e.text not in item:\n",
    "                                item.append(e.text)\n",
    "                                \n",
    "        \n",
    "        while True:\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            print(\"Last height \", last_height)\n",
    "            \n",
    "            source_code = driver.page_source\n",
    "            soup = BeautifulSoup(source_code, 'html.parser')\n",
    "            \n",
    "            ########left section\n",
    "            initial = soup.find_all(\"div\", class_=['sc-dkiTmt', 'cQiUWe'])\n",
    "            for y in initial:\n",
    "                left = y.find_all('div', class_ = ['sc-eiQXzm','cSojtf', 'commonStyles__StaticPositionedColumn-sc-6jqw77-1', 'bvouQZ'])\n",
    "                for l in left:\n",
    "                    pro = l.find_all('div', class_ = ['commonStyled__ContentArea-sc-17rimc7-0','ACCCm'])\n",
    "                    for pr in pro:\n",
    "                        p = pr.find_all('div', class_ = ['sc-dkiTmt','cQiUWe'])\n",
    "\n",
    "                        #pro heading section\n",
    "                        for i in p:\n",
    "                            pi = i.find_all('div', class_ = ['CreatorIntroSection__Title-sc-18c4e1x-0','bdBflQ'])\n",
    "                            for p in pi:\n",
    "                                #name section\n",
    "                                pname = p.find_all('div', class_ = ['sc-bdnylx','jckokO',  'ContentSectionStyle__SectionTitle-sc-1oywcqb-1', \"CreatorIntroSection__WordBrokenSectionTitle-sc-18c4e1x-1\",\"iJQLEl\" ,\"bSBRTB\"])\n",
    "                                for pn in pname:\n",
    "                                    if pn not in item:\n",
    "                                        item.append(pn)\n",
    "\n",
    "                                #link section\n",
    "                                plink = p.find_all('div', class_ = ['ChannelButtonGroup__Container-sc-1yqg9fu-0','zUbfY'])\n",
    "                                for pl in plink:\n",
    "                                    pm = pl.find_all('a', class_ = ['sc-hcmsuR','ARwUf','sc-dlnjPT','sc-fFSRdu','cuIYFB','goHICw'])\n",
    "                                    for a in pm:\n",
    "                                        if a.attrs['href'] not in item:\n",
    "                                            item.append(a.attrs['href'])\n",
    "\n",
    "                        #pro info section\n",
    "                        for j in p:  \n",
    "                            pp = j.find_all('div', class_ = ['creator-intro-foldable-content'])\n",
    "                            for jj in pp:\n",
    "                                mm = jj.find_all('div', class_ = ['FoldableContent__InnerContainer-eh1nn2-2','ionrXH'])\n",
    "                                for j in mm:\n",
    "                                    nn = j.find_all('div', class_ = ['SanitizeHtml__SanitizeHtmlContainer-ldtmln-0','gNRtXt'])\n",
    "                                    print(nn.text)\n",
    "                                \n",
    "#                                 if nn.text not in item:\n",
    "#                                     item.append(mm)\n",
    "                                    \n",
    "            # Scroll down to bottom\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(2)\n",
    "            # Calculate new scroll height and compare with last scroll height\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            print(\"New height \", new_height)\n",
    "\n",
    "            if new_height == last_height:\n",
    "                print(\"Quiting\")\n",
    "                driver.quit()\n",
    "                break\n",
    "            last_height = new_height\n",
    "        return\n",
    "    getdata(url)\n",
    "    all_item.append(item)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-attendance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
